{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report"
      ],
      "metadata": {
        "id": "I_woBjQDtDO7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch-tabular\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "WV1OJ_29ffEx",
        "outputId": "ec47531d-aede-40d3-c74d-465fb164126e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-tabular in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabular) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy<2.0,>1.20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabular) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabular) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabular) (1.6.1)\n",
            "Requirement already satisfied: pytorch-lightning<2.5.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabular) (2.4.0)\n",
            "Requirement already satisfied: omegaconf>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabular) (2.3.0)\n",
            "Requirement already satisfied: torchmetrics<1.6.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabular) (1.5.2)\n",
            "Requirement already satisfied: tensorboard!=2.5.0,>2.2.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabular) (2.18.0)\n",
            "Requirement already satisfied: protobuf<5.29.0,>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabular) (5.28.3)\n",
            "Requirement already satisfied: pytorch-tabnet==4.1 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabular) (4.1.0)\n",
            "Requirement already satisfied: PyYAML<6.1.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabular) (6.0.2)\n",
            "Requirement already satisfied: matplotlib>3.1 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabular) (3.10.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from pytorch-tabular) (7.7.1)\n",
            "Requirement already satisfied: einops<0.8.0,>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabular) (0.7.0)\n",
            "Requirement already satisfied: rich>=11.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabular) (13.9.4)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet==4.1->pytorch-tabular) (1.15.3)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.11/dist-packages (from pytorch-tabnet==4.1->pytorch-tabular) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>3.1->pytorch-tabular) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>3.1->pytorch-tabular) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>3.1->pytorch-tabular) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>3.1->pytorch-tabular) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>3.1->pytorch-tabular) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>3.1->pytorch-tabular) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>3.1->pytorch-tabular) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>3.1->pytorch-tabular) (2.9.0.post0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf>=2.3.0->pytorch-tabular) (4.9.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->pytorch-tabular) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.5->pytorch-tabular) (2025.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch-tabular) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning<2.5.0,>=2.0.0->pytorch-tabular) (4.13.2)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning<2.5.0,>=2.0.0->pytorch-tabular) (0.14.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.0.0->pytorch-tabular) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.0.0->pytorch-tabular) (2.19.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->pytorch-tabular) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->pytorch-tabular) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard!=2.5.0,>2.2.0->pytorch-tabular) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard!=2.5.0,>2.2.0->pytorch-tabular) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard!=2.5.0,>2.2.0->pytorch-tabular) (3.8)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard!=2.5.0,>2.2.0->pytorch-tabular) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard!=2.5.0,>2.2.0->pytorch-tabular) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard!=2.5.0,>2.2.0->pytorch-tabular) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard!=2.5.0,>2.2.0->pytorch-tabular) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->pytorch-tabular) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->pytorch-tabular) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->pytorch-tabular) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->pytorch-tabular) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->pytorch-tabular) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->pytorch-tabular) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->pytorch-tabular) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->pytorch-tabular) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->pytorch-tabular) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->pytorch-tabular) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->pytorch-tabular) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->pytorch-tabular) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->pytorch-tabular) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->pytorch-tabular) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->pytorch-tabular) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->pytorch-tabular) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->pytorch-tabular) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->pytorch-tabular) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->pytorch-tabular) (1.3.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->pytorch-tabular) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->pytorch-tabular) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->pytorch-tabular) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->pytorch-tabular) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->pytorch-tabular) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->pytorch-tabular) (3.0.15)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch-tabular) (3.11.15)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->pytorch-tabular) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->pytorch-tabular) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->pytorch-tabular) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->pytorch-tabular) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->pytorch-tabular) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->pytorch-tabular) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->pytorch-tabular) (6.4.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->pytorch-tabular) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->pytorch-tabular) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->pytorch-tabular) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->pytorch-tabular) (3.0.51)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->pytorch-tabular) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->pytorch-tabular) (4.9.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.0.0->pytorch-tabular) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard!=2.5.0,>2.2.0->pytorch-tabular) (3.0.2)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (6.5.7)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch-tabular) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch-tabular) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch-tabular) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch-tabular) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch-tabular) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch-tabular) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch-tabular) (1.20.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->pytorch-tabular) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->pytorch-tabular) (5.7.2)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (1.3.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->pytorch-tabular) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->pytorch-tabular) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->pytorch-tabular) (4.3.8)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (4.23.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.5.0,>=2.0.0->pytorch-tabular) (3.10)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (1.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (0.24.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (2.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (2.22)\n",
            "Requirement already satisfied: anyio>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (4.9.0)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (1.8.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->pytorch-tabular) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2"
      ],
      "metadata": {
        "id": "U5Jzx2KhZ5Nz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Obfuscate and Save Dataset ===\n",
        "###################################################Obfuscated_Strong.csv ##########################################################3##################\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import hashlib\n",
        "\n",
        "# === Load Data ===\n",
        "df = pd.read_csv(\"/content/TENNNNNNN100002023TENK.csv\")\n",
        "\n",
        "# === Strong Hash Obfuscation ===\n",
        "for col in ['Source IP', 'Destination IP', 'Flow ID']:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].apply(lambda x: hashlib.sha256(str(x).encode()).hexdigest())\n",
        "\n",
        "# === Encode Labels ===\n",
        "df['Label'] = df['Label'].map({'Benign': 0, 'Malicious': 1})\n",
        "df.dropna(subset=['Label'], inplace=True)\n",
        "\n",
        "\n",
        "# === Identify numeric features EXCLUDING the Label column\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.drop('Label')\n",
        "\n",
        "# === Add Gaussian Noise to Numeric Features ===\n",
        "\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.drop('Label')\n",
        "\n",
        "for col in numeric_cols:\n",
        "    std = df[col].std()\n",
        "    noise = np.random.normal(0, 0.3 * std, size=len(df))\n",
        "    df[col] += noise\n",
        "    df[col] = df[col].clip(lower=0)\n",
        "\n",
        "# === Binning (Discretization to 5 quantile bins) ===\n",
        "for col in numeric_cols:\n",
        "    try:\n",
        "        df[col] = pd.qcut(df[col], q=5, labels=False, duplicates='drop')\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "# === Feature Value Shuffling (Permutation) ===\n",
        "for col in numeric_cols:\n",
        "    df[col] = np.random.permutation(df[col].values)\n",
        "\n",
        "# === Random Value Masking (20%) ===\n",
        "mask_prob = 0.2\n",
        "for col in numeric_cols:\n",
        "    mask = np.random.rand(len(df)) < mask_prob\n",
        "    df.loc[mask, col] = 0\n",
        "\n",
        "# === Save the obfuscated dataset ===\n",
        "df.to_csv(\"NEWobfuscated_dataset.csv\", index=False)\n",
        "print(\"✅ Obfuscated dataset saved as 'obfuscated_dataset.csv'\")\n",
        "#########\n",
        "#########\n",
        "######################################\n",
        "######################################\n",
        "######################################\n",
        "#############################\n",
        "##################################################################################################################################################################################################################"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "56quDhkTfimW",
        "outputId": "28db9156-56d3-46d1-8a1c-7c0d82aaa8d6"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Obfuscated dataset saved as 'obfuscated_dataset.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Obfuscate and Save Dataset ===\n",
        "\n",
        "###########################################################################Obfuscated_Moderate.csv#############################################################\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import hashlib\n",
        "\n",
        "# === Load Data ===\n",
        "df = pd.read_csv(\"/content/TENNNNNNN100002023TENK.csv\")\n",
        "\n",
        "# === Strong Hash Obfuscation (IP fields only) ===\n",
        "# === Strong Hash Obfuscation ===\n",
        "for col in ['Source IP', 'Destination IP', 'Flow ID']:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].apply(lambda x: hashlib.sha256(str(x).encode()).hexdigest())\n",
        "\n",
        "# === Encode Labels ===\n",
        "df['Label'] = df['Label'].map({'Benign': 0, 'Malicious': 1})\n",
        "df.dropna(subset=['Label'], inplace=True)\n",
        "\n",
        "\n",
        "# === Identify numeric features EXCLUDING the Label column\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.drop('Label')\n",
        "\n",
        "# === Add Gaussian Noise to Numeric Features ===\n",
        "\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.drop('Label')\n",
        "\n",
        "for col in numeric_cols:\n",
        "    std = df[col].std()\n",
        "    noise = np.random.normal(0, 0.3 * std, size=len(df))\n",
        "    df[col] += noise\n",
        "    df[col] = df[col].clip(lower=0)\n",
        "# ❌ REMOVE Permutation – shuffling removes feature identity\n",
        "\n",
        "# === Binning (Discretization to 5 quantile bins) ===\n",
        "for col in numeric_cols:\n",
        "    try:\n",
        "        df[col] = pd.qcut(df[col], q=5, labels=False, duplicates='drop')\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "# === Reduce Random Masking to 10% ===\n",
        "mask_prob = 0.1\n",
        "for col in numeric_cols:\n",
        "    mask = np.random.rand(len(df)) < mask_prob\n",
        "    df.loc[mask, col] = 0\n",
        "\n",
        "# === Save the obfuscated dataset ===\n",
        "df.to_csv(\"SSSANAWobfuscated_dataset.csv\", index=False)\n",
        "print(\"✅ Obfuscated dataset saved as 'NEWobfuscated_dataset.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "9fzliS_HIUPV",
        "outputId": "c8f3ef5d-0333-4805-9344-a79fb3dc5454"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Obfuscated dataset saved as 'NEWobfuscated_dataset.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Obfuscate and Save Dataset ===\n",
        "##################################################################Obfuscated_Mild.csv##################################################################\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import hashlib\n",
        "\n",
        "# === Load Data ===\n",
        "df = pd.read_csv(\"/content/TENNNNNNN100002023TENK.csv\")\n",
        "\n",
        "# === Strong Hash Obfuscation (IP fields only) ===\n",
        "for col in ['Source IP', 'Destination IP', 'Flow ID']:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].apply(lambda x: hashlib.sha256(str(x).encode()).hexdigest())\n",
        "\n",
        "# === Encode Labels ===\n",
        "df['Label'] = df['Label'].map({'Benign': 0, 'Malicious': 1})\n",
        "df.dropna(subset=['Label'], inplace=True)\n",
        "\n",
        "# === Identify numeric features EXCLUDING the Label column\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.drop('Label')\n",
        "\n",
        "# === Add Mild Gaussian Noise to Numeric Features (0.1x std) ===\n",
        "for col in numeric_cols:\n",
        "    std = df[col].std()\n",
        "    noise = np.random.normal(0, 0.1 * std, size=len(df))\n",
        "    df[col] += noise\n",
        "    df[col] = df[col].clip(lower=0)\n",
        "\n",
        "# ❌ REMOVE Binning (qcut) – it destroys useful variance\n",
        "\n",
        "# ❌ REMOVE Permutation – shuffling removes feature identity\n",
        "\n",
        "# === Reduce Random Masking to 10% ===\n",
        "mask_prob = 0.1\n",
        "for col in numeric_cols:\n",
        "    mask = np.random.rand(len(df)) < mask_prob\n",
        "    df.loc[mask, col] = 0\n",
        "\n",
        "# === Save the obfuscated dataset ===\n",
        "df.to_csv(\"LESSSSNEWobfuscated_dataset.csv\", index=False)\n",
        "print(\"✅ Obfuscated dataset saved as 'NEWobfuscated_dataset.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "R4RdwLBKHonJ",
        "outputId": "712c8281-77c3-494f-cb08-553486b5fa6a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Obfuscated dataset saved as 'NEWobfuscated_dataset.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Load obfuscated data and classify ===\n",
        "###############################################################################################################################\n",
        "###############################################################################################################################\n",
        "#####################################################ExtraTreesClassifier###############################################\n",
        "###############################################################################################################################\n",
        "###############################################################################################################################\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "# === Load Obfuscated Dataset ===\n",
        "df = pd.read_csv(\"NEWobfuscated_dataset.csv\")\n",
        "\n",
        "# === Prepare Features and Labels ===\n",
        "X = df.drop(columns=['Label'], errors='ignore').select_dtypes(include=[np.number])\n",
        "y = df['Label']\n",
        "\n",
        "# === Random Projection Compression and Reconstruction ===\n",
        "d = X.shape[1]\n",
        "d_proj = int(0.3 * d)\n",
        "R = np.random.normal(size=(d_proj, d))\n",
        "X_proj = X.to_numpy() @ R.T\n",
        "X_rec = X_proj @ np.linalg.pinv(R).T\n",
        "X = pd.DataFrame(X_rec, columns=X.columns)\n",
        "\n",
        "# === Flip 10% of Labels ===\n",
        "flip_indices = np.random.choice(len(y), size=int(0.1 * len(y)), replace=False)\n",
        "y.iloc[flip_indices] = 1 - y.iloc[flip_indices]\n",
        "\n",
        "# === Replace NaNs and Scale ===\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X.fillna(0, inplace=True)\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "# === Train/Test Split (Stratified) ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# === Train Extra Trees Classifier ===\n",
        "model = ExtraTreesClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Evaluate ===\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"✅ Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"✅ F1 Score:\", f1_score(y_test, y_pred, average='macro'))\n",
        "print(\"\\n✅ Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "h28rg3rzueyM",
        "outputId": "c29a7155-8bd4-485e-a9bd-aeb3da600246"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-68-afbdf850276d>:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  y.iloc[flip_indices] = 1 - y.iloc[flip_indices]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Accuracy: 0.5026666666666667\n",
            "✅ F1 Score: 0.33451641526175685\n",
            "\n",
            "✅ Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1492\n",
            "           1       0.50      1.00      0.67      1508\n",
            "\n",
            "    accuracy                           0.50      3000\n",
            "   macro avg       0.25      0.50      0.33      3000\n",
            "weighted avg       0.25      0.50      0.34      3000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################################################################\n",
        "###############################################################################################################################\n",
        "#####################################################LightGBM with imbalance handling###############################################\n",
        "###############################################################################################################################\n",
        "###############################################################################################################################\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import lightgbm as lgb\n",
        "\n",
        "# === Load obfuscated dataset ===\n",
        "df = pd.read_csv(\"NEWobfuscated_dataset.csv\")\n",
        "\n",
        "# === Keep only binary labels ===\n",
        "df = df[df['Label'].isin([0, 1])]\n",
        "X = df.drop(columns=['Label'], errors='ignore').select_dtypes(include=[np.number])\n",
        "y = df['Label']\n",
        "\n",
        "# === Drop constant columns ===\n",
        "X = X.loc[:, (X != X.iloc[0]).any()]\n",
        "\n",
        "# === Scale and clean ===\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X.fillna(0, inplace=True)\n",
        "X_scaled = StandardScaler().fit_transform(X)\n",
        "\n",
        "# === Train/Test Split (Stratified) ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# === LightGBM with imbalance handling ===\n",
        "model = lgb.LGBMClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    is_unbalance=True,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# === Evaluation ===\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"✅ Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"✅ F1 Score:\", f1_score(y_test, y_pred, average='macro'))\n",
        "print(\"\\n✅ Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gonDkwf6vBC1",
        "outputId": "dbf235c6-bb5e-43f4-d1f6-49c69c018e30"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 3500, number of negative: 3500\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055952 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 343\n",
            "[LightGBM] [Info] Number of data points in the train set: 7000, number of used features: 74\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "✅ Accuracy: 0.5033333333333333\n",
            "✅ F1 Score: 0.503325386539518\n",
            "\n",
            "✅ Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.50      0.50      1500\n",
            "           1       0.50      0.51      0.51      1500\n",
            "\n",
            "    accuracy                           0.50      3000\n",
            "   macro avg       0.50      0.50      0.50      3000\n",
            "weighted avg       0.50      0.50      0.50      3000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################################################################\n",
        "###############################################################################################################################\n",
        "#####################################################XGBoost =###############################################\n",
        "###############################################################################################################################\n",
        "###############################################################################################################################\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from collections import Counter\n",
        "\n",
        "# === Load and preprocess ===\n",
        "df = pd.read_csv(\"NEWobfuscated_dataset.csv\")\n",
        "df = df[df['Label'].isin([0, 1])]\n",
        "X = df.drop(columns=['Label'], errors='ignore').select_dtypes(include=[np.number])\n",
        "y = df['Label']\n",
        "X = X.loc[:, (X != X.iloc[0]).any()]\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X.fillna(0, inplace=True)\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "# === Split ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# === Compute class weights ===\n",
        "counter = Counter(y_train)\n",
        "scale_pos_weight = counter[0] / counter[1]  # balancing classes\n",
        "\n",
        "# === XGBoost Classifier with tuning and early stopping ===\n",
        "model = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_test, y_test)],\n",
        "\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "# === Evaluate ===\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"✅ Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"✅ F1 Score:\", f1_score(y_test, y_pred, average='macro'))\n",
        "print(\"\\n✅ Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "G82QRxYSvk4u",
        "outputId": "0fd4be0d-368d-44b5-c892-aee5f7163909"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:07:44] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Accuracy: 0.5063333333333333\n",
            "✅ F1 Score: 0.5062015988932158\n",
            "\n",
            "✅ Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.49      0.50      1500\n",
            "           1       0.51      0.52      0.51      1500\n",
            "\n",
            "    accuracy                           0.51      3000\n",
            "   macro avg       0.51      0.51      0.51      3000\n",
            "weighted avg       0.51      0.51      0.51      3000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################################################################\n",
        "###############################################################################################################################\n",
        "#############################################ensambel= =###############################################\n",
        "###############################################################################################################################\n",
        "###############################################################################################################################\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from collections import Counter\n",
        "\n",
        "# === Load and preprocess ===\n",
        "df = pd.read_csv(\"/content/NEWobfuscated_dataset (1).csv\")\n",
        "df = df[df['Label'].isin([0, 1])]\n",
        "X = df.drop(columns=['Label'], errors='ignore').select_dtypes(include=[np.number])\n",
        "y = df['Label']\n",
        "X = X.loc[:, (X != X.iloc[0]).any()]\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X.fillna(0, inplace=True)\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "# === Train/test split ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# === Class weight for XGBoost ===\n",
        "counter = Counter(y_train)\n",
        "scale_pos_weight = counter[0] / counter[1]\n",
        "\n",
        "# === Define individual models ===\n",
        "lgb_model = LGBMClassifier(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    is_unbalance=True,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "mlp_model = MLPClassifier(\n",
        "    hidden_layer_sizes=(64, 32),\n",
        "    max_iter=200,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# === Ensemble with soft voting ===\n",
        "ensemble = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('lgb', lgb_model),\n",
        "        ('xgb', xgb_model),\n",
        "        ('mlp', mlp_model)\n",
        "    ],\n",
        "    voting='soft'  # use probability averaging\n",
        ")\n",
        "\n",
        "# === Train ensemble ===\n",
        "ensemble.fit(X_train, y_train)\n",
        "\n",
        "# === Evaluate ===\n",
        "y_pred = ensemble.predict(X_test)\n",
        "print(\"✅ Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"✅ F1 Score:\", f1_score(y_test, y_pred, average='macro'))\n",
        "print(\"\\n✅ Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0WkrjHWHy5Wm",
        "outputId": "d80193fb-d94a-4561-b10c-e00da646e23a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 3500, number of negative: 3500\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053603 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 341\n",
            "[LightGBM] [Info] Number of data points in the train set: 7000, number of used features: 74\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [15:24:39] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Accuracy: 0.5063333333333333\n",
            "✅ F1 Score: 0.5063043149980704\n",
            "\n",
            "✅ Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.50      0.50      1500\n",
            "           1       0.51      0.51      0.51      1500\n",
            "\n",
            "    accuracy                           0.51      3000\n",
            "   macro avg       0.51      0.51      0.51      3000\n",
            "weighted avg       0.51      0.51      0.51      3000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################################################################\n",
        "###############################################################################################################################\n",
        "##############################################TabNet === =###############################################\n",
        "###############################################################################################################################\n",
        "###############################################################################################################################\n",
        "\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "# === Load Data ===\n",
        "df = pd.read_csv(\"/content/SSSANAWobfuscated_dataset.csv\")\n",
        "print(df['Label'].unique())\n",
        "# === Convert Label to 0/1 ===\n",
        "df = df[df['Label'].isin([0, 1])]\n",
        "\n",
        "X = df.drop(columns=['Label'], errors='ignore').select_dtypes(include=[np.number])\n",
        "X = X.loc[:, (X != X.iloc[0]).any()]\n",
        "y = df['Label'].astype(int)\n",
        "\n",
        "# === Scale & Split ===\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X.fillna(0, inplace=True)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# === Train TabNet ===\n",
        "clf = TabNetClassifier()\n",
        "clf.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_test, y_test)],\n",
        "    eval_name=['test'],\n",
        "    eval_metric=['accuracy'],\n",
        "    max_epochs=3,##################################*********************\n",
        "    patience=3,\n",
        "    batch_size=512,\n",
        "    virtual_batch_size=128,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "# === Evaluate ===\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"✅ Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"✅ F1 Score:\", f1_score(y_test, y_pred, average='macro'))\n",
        "print(\"\\n✅ Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MXF7h_4NvqJl",
        "outputId": "e039c8ec-799b-4008-a1f5-bc5f1543e2b9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.68598 | test_accuracy: 0.67933 |  0:00:00s\n",
            "epoch 1  | loss: 0.46656 | test_accuracy: 0.83167 |  0:00:01s\n",
            "epoch 2  | loss: 0.38507 | test_accuracy: 0.84667 |  0:00:02s\n",
            "epoch 3  | loss: 0.34062 | test_accuracy: 0.88567 |  0:00:03s\n",
            "epoch 4  | loss: 0.2935  | test_accuracy: 0.89433 |  0:00:03s\n",
            "epoch 5  | loss: 0.24939 | test_accuracy: 0.90867 |  0:00:04s\n",
            "epoch 6  | loss: 0.21997 | test_accuracy: 0.925   |  0:00:05s\n",
            "epoch 7  | loss: 0.19859 | test_accuracy: 0.93133 |  0:00:06s\n",
            "epoch 8  | loss: 0.1879  | test_accuracy: 0.936   |  0:00:07s\n",
            "epoch 9  | loss: 0.16575 | test_accuracy: 0.941   |  0:00:08s\n",
            "epoch 10 | loss: 0.15359 | test_accuracy: 0.94133 |  0:00:08s\n",
            "epoch 11 | loss: 0.14411 | test_accuracy: 0.94333 |  0:00:09s\n",
            "epoch 12 | loss: 0.1356  | test_accuracy: 0.93967 |  0:00:10s\n",
            "epoch 13 | loss: 0.12501 | test_accuracy: 0.948   |  0:00:11s\n",
            "epoch 14 | loss: 0.11771 | test_accuracy: 0.94967 |  0:00:11s\n",
            "epoch 15 | loss: 0.11298 | test_accuracy: 0.95567 |  0:00:12s\n",
            "epoch 16 | loss: 0.10179 | test_accuracy: 0.94967 |  0:00:13s\n",
            "epoch 17 | loss: 0.1052  | test_accuracy: 0.95733 |  0:00:13s\n",
            "epoch 18 | loss: 0.10442 | test_accuracy: 0.95767 |  0:00:14s\n",
            "epoch 19 | loss: 0.09413 | test_accuracy: 0.96033 |  0:00:15s\n",
            "epoch 20 | loss: 0.08846 | test_accuracy: 0.96167 |  0:00:15s\n",
            "epoch 21 | loss: 0.08261 | test_accuracy: 0.96533 |  0:00:16s\n",
            "epoch 22 | loss: 0.08203 | test_accuracy: 0.965   |  0:00:17s\n",
            "epoch 23 | loss: 0.07461 | test_accuracy: 0.96633 |  0:00:18s\n",
            "epoch 24 | loss: 0.07241 | test_accuracy: 0.95867 |  0:00:19s\n",
            "epoch 25 | loss: 0.07807 | test_accuracy: 0.967   |  0:00:20s\n",
            "epoch 26 | loss: 0.07778 | test_accuracy: 0.96367 |  0:00:20s\n",
            "epoch 27 | loss: 0.07553 | test_accuracy: 0.96567 |  0:00:21s\n",
            "epoch 28 | loss: 0.07366 | test_accuracy: 0.96767 |  0:00:22s\n",
            "epoch 29 | loss: 0.06874 | test_accuracy: 0.96567 |  0:00:23s\n",
            "epoch 30 | loss: 0.06484 | test_accuracy: 0.96667 |  0:00:23s\n",
            "epoch 31 | loss: 0.06544 | test_accuracy: 0.96833 |  0:00:24s\n",
            "epoch 32 | loss: 0.05954 | test_accuracy: 0.969   |  0:00:25s\n",
            "epoch 33 | loss: 0.05672 | test_accuracy: 0.96533 |  0:00:25s\n",
            "epoch 34 | loss: 0.05236 | test_accuracy: 0.96867 |  0:00:26s\n",
            "epoch 35 | loss: 0.04886 | test_accuracy: 0.967   |  0:00:27s\n",
            "epoch 36 | loss: 0.05265 | test_accuracy: 0.96767 |  0:00:27s\n",
            "epoch 37 | loss: 0.04965 | test_accuracy: 0.96533 |  0:00:28s\n",
            "epoch 38 | loss: 0.04628 | test_accuracy: 0.97    |  0:00:29s\n",
            "epoch 39 | loss: 0.04753 | test_accuracy: 0.96833 |  0:00:30s\n",
            "epoch 40 | loss: 0.04417 | test_accuracy: 0.96367 |  0:00:31s\n",
            "epoch 41 | loss: 0.04579 | test_accuracy: 0.96967 |  0:00:32s\n",
            "epoch 42 | loss: 0.04027 | test_accuracy: 0.96933 |  0:00:32s\n",
            "epoch 43 | loss: 0.03853 | test_accuracy: 0.97033 |  0:00:33s\n",
            "epoch 44 | loss: 0.0406  | test_accuracy: 0.97067 |  0:00:34s\n",
            "epoch 45 | loss: 0.03668 | test_accuracy: 0.96867 |  0:00:35s\n",
            "epoch 46 | loss: 0.04174 | test_accuracy: 0.969   |  0:00:35s\n",
            "epoch 47 | loss: 0.03653 | test_accuracy: 0.96767 |  0:00:36s\n",
            "epoch 48 | loss: 0.03842 | test_accuracy: 0.96933 |  0:00:37s\n",
            "epoch 49 | loss: 0.03475 | test_accuracy: 0.96967 |  0:00:37s\n",
            "epoch 50 | loss: 0.03346 | test_accuracy: 0.969   |  0:00:38s\n",
            "epoch 51 | loss: 0.03123 | test_accuracy: 0.96667 |  0:00:39s\n",
            "epoch 52 | loss: 0.03106 | test_accuracy: 0.968   |  0:00:39s\n",
            "epoch 53 | loss: 0.03063 | test_accuracy: 0.96667 |  0:00:40s\n",
            "epoch 54 | loss: 0.02918 | test_accuracy: 0.96833 |  0:00:41s\n",
            "\n",
            "Early stopping occurred at epoch 54 with best_epoch = 44 and best_test_accuracy = 0.97067\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Accuracy: 0.9706666666666667\n",
            "✅ F1 Score: 0.9706664580725908\n",
            "\n",
            "✅ Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      1500\n",
            "           1       0.97      0.97      0.97      1500\n",
            "\n",
            "    accuracy                           0.97      3000\n",
            "   macro avg       0.97      0.97      0.97      3000\n",
            "weighted avg       0.97      0.97      0.97      3000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch_tabnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "xMgL4dUfvZil",
        "outputId": "e353199e-610b-43b1-9379-26d3861b538d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_tabnet\n",
            "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from pytorch_tabnet) (2.0.2)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.11/dist-packages (from pytorch_tabnet) (1.6.1)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.11/dist-packages (from pytorch_tabnet) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.11/dist-packages (from pytorch_tabnet) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.11/dist-packages (from pytorch_tabnet) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit_learn>0.21->pytorch_tabnet) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.3->pytorch_tabnet)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.3->pytorch_tabnet)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.3->pytorch_tabnet)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.3->pytorch_tabnet)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.3->pytorch_tabnet)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.3->pytorch_tabnet)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.3->pytorch_tabnet)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.3->pytorch_tabnet)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.3->pytorch_tabnet)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.3->pytorch_tabnet)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3->pytorch_tabnet) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.3->pytorch_tabnet) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.3->pytorch_tabnet) (3.0.2)\n",
            "Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch_tabnet\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch_tabnet-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################################################################\n",
        "###############################################################################################################################\n",
        "##############################################TabNet === =###############################################\n",
        "###############################################################################################################################\n",
        "###############################################################################################################################\n",
        "\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "# === Load Data ===\n",
        "df = pd.read_csv(\"/content/LESSSSNEWobfuscated_dataset.csv\")\n",
        "print(df['Label'].unique())\n",
        "# === Convert Label to 0/1 ===\n",
        "df = df[df['Label'].isin([0, 1])]\n",
        "\n",
        "X = df.drop(columns=['Label'], errors='ignore').select_dtypes(include=[np.number])\n",
        "X = X.loc[:, (X != X.iloc[0]).any()]\n",
        "y = df['Label'].astype(int)\n",
        "\n",
        "# === Scale & Split ===\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X.fillna(0, inplace=True)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# === Train TabNet ===\n",
        "clf = TabNetClassifier()\n",
        "clf.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_test, y_test)],\n",
        "    eval_name=['test'],\n",
        "    eval_metric=['accuracy'],\n",
        "    max_epochs=100,##################################*********************\n",
        "    patience=10,\n",
        "    batch_size=512,\n",
        "    virtual_batch_size=128,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "# === Evaluate ===\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"✅ Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"✅ F1 Score:\", f1_score(y_test, y_pred, average='macro'))\n",
        "print(\"\\n✅ Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "yhuF-n-dvTKS",
        "outputId": "aa12b7ae-e6f3-43bb-c02c-b2ff2664a1ed"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.58336 | test_accuracy: 0.81667 |  0:00:01s\n",
            "epoch 1  | loss: 0.27628 | test_accuracy: 0.915   |  0:00:03s\n",
            "epoch 2  | loss: 0.19401 | test_accuracy: 0.94833 |  0:00:04s\n",
            "epoch 3  | loss: 0.1497  | test_accuracy: 0.96167 |  0:00:05s\n",
            "epoch 4  | loss: 0.12746 | test_accuracy: 0.968   |  0:00:06s\n",
            "epoch 5  | loss: 0.10197 | test_accuracy: 0.96833 |  0:00:06s\n",
            "epoch 6  | loss: 0.0831  | test_accuracy: 0.97367 |  0:00:07s\n",
            "epoch 7  | loss: 0.07488 | test_accuracy: 0.973   |  0:00:08s\n",
            "epoch 8  | loss: 0.0744  | test_accuracy: 0.97967 |  0:00:09s\n",
            "epoch 9  | loss: 0.07976 | test_accuracy: 0.978   |  0:00:10s\n",
            "epoch 10 | loss: 0.07689 | test_accuracy: 0.975   |  0:00:11s\n",
            "epoch 11 | loss: 0.07265 | test_accuracy: 0.97533 |  0:00:12s\n",
            "epoch 12 | loss: 0.07061 | test_accuracy: 0.979   |  0:00:13s\n",
            "epoch 13 | loss: 0.06081 | test_accuracy: 0.97733 |  0:00:15s\n",
            "epoch 14 | loss: 0.06099 | test_accuracy: 0.981   |  0:00:17s\n",
            "epoch 15 | loss: 0.05423 | test_accuracy: 0.97967 |  0:00:18s\n",
            "epoch 16 | loss: 0.05054 | test_accuracy: 0.982   |  0:00:18s\n",
            "epoch 17 | loss: 0.0552  | test_accuracy: 0.98267 |  0:00:19s\n",
            "epoch 18 | loss: 0.04973 | test_accuracy: 0.98333 |  0:00:20s\n",
            "epoch 19 | loss: 0.05044 | test_accuracy: 0.98267 |  0:00:20s\n",
            "epoch 20 | loss: 0.04071 | test_accuracy: 0.98133 |  0:00:21s\n",
            "epoch 21 | loss: 0.03923 | test_accuracy: 0.98267 |  0:00:22s\n",
            "epoch 22 | loss: 0.04925 | test_accuracy: 0.98133 |  0:00:22s\n",
            "epoch 23 | loss: 0.04415 | test_accuracy: 0.98333 |  0:00:23s\n",
            "epoch 24 | loss: 0.04321 | test_accuracy: 0.98433 |  0:00:24s\n",
            "epoch 25 | loss: 0.03977 | test_accuracy: 0.98167 |  0:00:25s\n",
            "epoch 26 | loss: 0.04279 | test_accuracy: 0.98233 |  0:00:25s\n",
            "epoch 27 | loss: 0.03884 | test_accuracy: 0.98167 |  0:00:26s\n",
            "epoch 28 | loss: 0.03781 | test_accuracy: 0.98467 |  0:00:27s\n",
            "epoch 29 | loss: 0.03734 | test_accuracy: 0.98567 |  0:00:27s\n",
            "epoch 30 | loss: 0.03284 | test_accuracy: 0.98633 |  0:00:28s\n",
            "epoch 31 | loss: 0.03311 | test_accuracy: 0.98533 |  0:00:29s\n",
            "epoch 32 | loss: 0.03353 | test_accuracy: 0.98533 |  0:00:30s\n",
            "epoch 33 | loss: 0.03089 | test_accuracy: 0.98733 |  0:00:31s\n",
            "epoch 34 | loss: 0.034   | test_accuracy: 0.98667 |  0:00:31s\n",
            "epoch 35 | loss: 0.03105 | test_accuracy: 0.98667 |  0:00:32s\n",
            "epoch 36 | loss: 0.02762 | test_accuracy: 0.98667 |  0:00:33s\n",
            "epoch 37 | loss: 0.02432 | test_accuracy: 0.987   |  0:00:33s\n",
            "epoch 38 | loss: 0.02637 | test_accuracy: 0.986   |  0:00:34s\n",
            "epoch 39 | loss: 0.03711 | test_accuracy: 0.98533 |  0:00:35s\n",
            "epoch 40 | loss: 0.03162 | test_accuracy: 0.987   |  0:00:36s\n",
            "epoch 41 | loss: 0.02906 | test_accuracy: 0.98733 |  0:00:36s\n",
            "epoch 42 | loss: 0.02808 | test_accuracy: 0.987   |  0:00:37s\n",
            "epoch 43 | loss: 0.02559 | test_accuracy: 0.98733 |  0:00:38s\n",
            "\n",
            "Early stopping occurred at epoch 43 with best_epoch = 33 and best_test_accuracy = 0.98733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Accuracy: 0.9873333333333333\n",
            "✅ F1 Score: 0.987333282666464\n",
            "\n",
            "✅ Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      1500\n",
            "           1       0.99      0.99      0.99      1500\n",
            "\n",
            "    accuracy                           0.99      3000\n",
            "   macro avg       0.99      0.99      0.99      3000\n",
            "weighted avg       0.99      0.99      0.99      3000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "###############################################################################################################################\n",
        "###############################################################################################################################\n",
        "##############################################TabNet === =###############################################\n",
        "###############################################################################################################################\n",
        "###############################################################################################################################\n",
        "\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#*********************************************Normal data *******************************************************************************************************\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "# === Load Data ===\n",
        "df = pd.read_csv(\"/content/TENNNNNNN100002023TENK.csv\")\n",
        "\n",
        "# === Convert Label to 0/1 ===\n",
        "df = df[df['Label'].isin(['Benign', 'Malicious'])]  # Filter relevant rows only\n",
        "df['Label'] = df['Label'].map({'Benign': 0, 'Malicious': 1})  # Encode to 0/1\n",
        "\n",
        "# === Prepare Features ===\n",
        "X = df.drop(columns=['Label'], errors='ignore').select_dtypes(include=[np.number])\n",
        "X = X.loc[:, (X != X.iloc[0]).any()]  # Drop constant columns\n",
        "y = df['Label'].astype(int)\n",
        "\n",
        "# === Scale & Clean ===\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X.fillna(0, inplace=True)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# === Split ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# === Train TabNet ===\n",
        "clf = TabNetClassifier()\n",
        "clf.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_test, y_test)],\n",
        "    eval_name=['test'],\n",
        "    eval_metric=['accuracy'],\n",
        "    max_epochs=100,\n",
        "    patience=10,\n",
        "    batch_size=512,\n",
        "    virtual_batch_size=128,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "# === Evaluate ===\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"✅ Accuracy normalll:\", accuracy_score(y_test, y_pred))\n",
        "print(\"✅ F1 Score:\", f1_score(y_test, y_pred, average='macro'))\n",
        "print(\"\\n✅ Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "D1PTECzj0tqR",
        "outputId": "986449c2-95a9-4308-8db4-f415537c9f8f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.00124 | test_accuracy: 1.0     |  0:00:00s\n",
            "epoch 1  | loss: 0.00114 | test_accuracy: 1.0     |  0:00:00s\n",
            "epoch 2  | loss: 0.00103 | test_accuracy: 1.0     |  0:00:00s\n",
            "epoch 3  | loss: 0.00095 | test_accuracy: 1.0     |  0:00:00s\n",
            "epoch 4  | loss: 0.00091 | test_accuracy: 1.0     |  0:00:00s\n",
            "epoch 5  | loss: 0.00081 | test_accuracy: 1.0     |  0:00:00s\n",
            "epoch 6  | loss: 0.00073 | test_accuracy: 1.0     |  0:00:00s\n",
            "epoch 7  | loss: 0.00065 | test_accuracy: 1.0     |  0:00:01s\n",
            "epoch 8  | loss: 0.00057 | test_accuracy: 1.0     |  0:00:01s\n",
            "epoch 9  | loss: 0.00052 | test_accuracy: 1.0     |  0:00:01s\n",
            "epoch 10 | loss: 0.00049 | test_accuracy: 1.0     |  0:00:02s\n",
            "\n",
            "Early stopping occurred at epoch 10 with best_epoch = 0 and best_test_accuracy = 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Accuracy normalll: 1.0\n",
            "✅ F1 Score: 1.0\n",
            "\n",
            "✅ Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       643\n",
            "\n",
            "    accuracy                           1.00       643\n",
            "   macro avg       1.00      1.00      1.00       643\n",
            "weighted avg       1.00      1.00      1.00       643\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ppf = pd.read_csv(\"/content/NEWobfuscated_dataset (1).csv\")"
      ],
      "metadata": {
        "id": "EpjQc7cLxfE1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total samples:\", len(ppf))\n",
        "# === Show unique label distribution before any processing ===\n",
        "print(ppf['Label'].value_counts())\n",
        "print(\"\\nUnique classes:\", ppf['Label'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Q53W6h_lxi8d",
        "outputId": "e5b6cddf-08c7-44f3-adec-7e90f423eaf0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 10000\n",
            "Label\n",
            "0    5000\n",
            "1    5000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Unique classes: [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################################################################\n",
        "###############################################################################################################################\n",
        "##############################################TabNet === =###############################################\n",
        "###############################################################################################################################\n",
        "###############################################################################################################################\n",
        "\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "#****************************************************************************************************************************************************\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "# === Load Data ===\n",
        "df = pd.read_csv(\"/content/NEWobfuscated_dataset (1).csv\")\n",
        "print(df['Label'].unique())\n",
        "# === Convert Label to 0/1 ===\n",
        "df = df[df['Label'].isin([0, 1])]\n",
        "\n",
        "X = df.drop(columns=['Label'], errors='ignore').select_dtypes(include=[np.number])\n",
        "X = X.loc[:, (X != X.iloc[0]).any()]\n",
        "y = df['Label'].astype(int)\n",
        "\n",
        "# === Scale & Split ===\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X.fillna(0, inplace=True)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# === Train TabNet ===\n",
        "clf = TabNetClassifier()\n",
        "clf.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_test, y_test)],\n",
        "    eval_name=['test'],\n",
        "    eval_metric=['accuracy'],\n",
        "    max_epochs=100,##################################*********************\n",
        "    patience=10,\n",
        "    batch_size=512,\n",
        "    virtual_batch_size=128,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "# === Evaluate ===\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"✅ Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"✅ F1 Score:\", f1_score(y_test, y_pred, average='macro'))\n",
        "print(\"\\n✅ Classification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tKHNm_ijxIWM",
        "outputId": "812c20bb-1012-455b-b4e1-8793b090afdd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 0.84583 | test_accuracy: 0.49633 |  0:00:01s\n",
            "epoch 1  | loss: 0.70098 | test_accuracy: 0.484   |  0:00:02s\n",
            "epoch 2  | loss: 0.6947  | test_accuracy: 0.49367 |  0:00:03s\n",
            "epoch 3  | loss: 0.69382 | test_accuracy: 0.49867 |  0:00:04s\n",
            "epoch 4  | loss: 0.69363 | test_accuracy: 0.48667 |  0:00:05s\n",
            "epoch 5  | loss: 0.69319 | test_accuracy: 0.48867 |  0:00:06s\n",
            "epoch 6  | loss: 0.69221 | test_accuracy: 0.49633 |  0:00:06s\n",
            "epoch 7  | loss: 0.69085 | test_accuracy: 0.50433 |  0:00:07s\n",
            "epoch 8  | loss: 0.69086 | test_accuracy: 0.5     |  0:00:08s\n",
            "epoch 9  | loss: 0.69188 | test_accuracy: 0.50033 |  0:00:09s\n",
            "epoch 10 | loss: 0.69063 | test_accuracy: 0.508   |  0:00:10s\n",
            "epoch 11 | loss: 0.68911 | test_accuracy: 0.494   |  0:00:11s\n",
            "epoch 12 | loss: 0.6904  | test_accuracy: 0.50467 |  0:00:11s\n",
            "epoch 13 | loss: 0.6893  | test_accuracy: 0.50433 |  0:00:12s\n",
            "epoch 14 | loss: 0.6912  | test_accuracy: 0.50633 |  0:00:13s\n",
            "epoch 15 | loss: 0.68849 | test_accuracy: 0.504   |  0:00:14s\n",
            "epoch 16 | loss: 0.68799 | test_accuracy: 0.51133 |  0:00:14s\n",
            "epoch 17 | loss: 0.68905 | test_accuracy: 0.50867 |  0:00:15s\n",
            "epoch 18 | loss: 0.68727 | test_accuracy: 0.49967 |  0:00:16s\n",
            "epoch 19 | loss: 0.68639 | test_accuracy: 0.493   |  0:00:16s\n",
            "epoch 20 | loss: 0.68563 | test_accuracy: 0.511   |  0:00:17s\n",
            "epoch 21 | loss: 0.68429 | test_accuracy: 0.50567 |  0:00:18s\n",
            "epoch 22 | loss: 0.68077 | test_accuracy: 0.50067 |  0:00:19s\n",
            "epoch 23 | loss: 0.68075 | test_accuracy: 0.503   |  0:00:19s\n",
            "epoch 24 | loss: 0.67889 | test_accuracy: 0.48733 |  0:00:20s\n",
            "epoch 25 | loss: 0.67917 | test_accuracy: 0.48467 |  0:00:21s\n",
            "epoch 26 | loss: 0.68121 | test_accuracy: 0.487   |  0:00:22s\n",
            "\n",
            "Early stopping occurred at epoch 26 with best_epoch = 16 and best_test_accuracy = 0.51133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Accuracy: 0.5113333333333333\n",
            "✅ F1 Score: 0.490402227676883\n",
            "\n",
            "✅ Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.31      0.39      1500\n",
            "           1       0.51      0.71      0.59      1500\n",
            "\n",
            "    accuracy                           0.51      3000\n",
            "   macro avg       0.51      0.51      0.49      3000\n",
            "weighted avg       0.51      0.51      0.49      3000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total samples:\", len(EW))\n",
        "# === Show unique label distribution before any processing ===\n",
        "print(EW['Label'].value_counts())\n",
        "print(\"\\nUnique classes:\", EW['Label'].unique())"
      ],
      "metadata": {
        "id": "RrvsT6Uv72Fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.semi_supervised import LabelSpreading\n",
        "\n",
        "# === Load the obfuscated dataset ===\n",
        "df = pd.read_csv(\"NEWobfuscated_dataset.csv\")\n",
        "df = df[df['Label'].isin([0, 1])]\n",
        "\n",
        "# === Preprocess features ===\n",
        "X = df.drop(columns=['Label'], errors='ignore').select_dtypes(include=[np.number])\n",
        "X = X.loc[:, X.nunique() > 1]\n",
        "y = df['Label'].astype(int)\n",
        "\n",
        "# Clean NaNs/Infs\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X.fillna(0, inplace=True)\n",
        "\n",
        "# === Scale features ===\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# === Train-test split ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# === 1. Logistic Regression ===\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred_logreg = logreg.predict(X_test)\n",
        "print(\"🔵 Logistic Regression\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_logreg))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_logreg, average='macro'))\n",
        "print(classification_report(y_test, y_pred_logreg))\n",
        "\n",
        "# === 2. k-Nearest Neighbors ===\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "print(\"\\n🟢 k-Nearest Neighbors\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_knn, average='macro'))\n",
        "print(classification_report(y_test, y_pred_knn))\n",
        "\n",
        "# === 3. Label Spreading (Semi-Supervised) ===\n",
        "X_combined = np.vstack([X_train, X_test])\n",
        "y_combined = np.concatenate([y_train, [-1] * len(y_test)])  # Simulate unlabeled test set\n",
        "\n",
        "label_spread = LabelSpreading(kernel='knn', alpha=0.2)\n",
        "label_spread.fit(X_combined, y_combined)\n",
        "y_pred_ls = label_spread.transduction_[-len(y_test):]\n",
        "print(\"\\n🟣 Label Spreading\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_ls))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred_ls, average='macro'))\n",
        "print(classification_report(y_test, y_pred_ls))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EAlKgGojDPhd",
        "outputId": "dede0f60-4831-4340-ebca-9bb688912ead"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔵 Logistic Regression\n",
            "Accuracy: 0.5063333333333333\n",
            "F1 Score: 0.5062582297240548\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.49      0.50      1500\n",
            "           1       0.51      0.52      0.51      1500\n",
            "\n",
            "    accuracy                           0.51      3000\n",
            "   macro avg       0.51      0.51      0.51      3000\n",
            "weighted avg       0.51      0.51      0.51      3000\n",
            "\n",
            "\n",
            "🟢 k-Nearest Neighbors\n",
            "Accuracy: 0.4836666666666667\n",
            "F1 Score: 0.48316999302996844\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.45      0.47      1500\n",
            "           1       0.48      0.51      0.50      1500\n",
            "\n",
            "    accuracy                           0.48      3000\n",
            "   macro avg       0.48      0.48      0.48      3000\n",
            "weighted avg       0.48      0.48      0.48      3000\n",
            "\n",
            "\n",
            "🟣 Label Spreading\n",
            "Accuracy: 0.49\n",
            "F1 Score: 0.49287552911597965\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.48      0.48      1500\n",
            "           1       0.49      0.51      0.50      1500\n",
            "\n",
            "    accuracy                           0.49      3000\n",
            "   macro avg       0.49      0.49      0.49      3000\n",
            "weighted avg       0.49      0.49      0.49      3000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
